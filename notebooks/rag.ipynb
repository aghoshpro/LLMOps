{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e3aca6-5d5d-483f-b833-2a99f237c91a",
   "metadata": {},
   "source": [
    "# System pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95160ce-f683-4474-a85a-cf48aa7923af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# os.environ[\"OLLAMA_BASE_URL\"] = \"http://localhost:11434\"\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ea1f51-b97b-4442-a311-1f0af39bee0f",
   "metadata": {},
   "source": [
    "# Data Wrangling pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbc2fff-3bd0-4af6-b7ca-ad0319a8c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# np.set_printoptions(threshold=sys.maxsize) # to display the entire array\n",
    "import pandas as pd\n",
    "#import polars as pr # new pkg similar to pandas but faster\n",
    "import glob\n",
    "import urllib.request\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e148d42-e69f-4bc4-85a7-3257808b903e",
   "metadata": {},
   "source": [
    "# Data Viz pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ae86fd-8303-4b8a-acd7-014bceafc16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "# plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100 # e.g. default 100 but 300 would be a really fine plot, but slower\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "# from PIL import Image # default but in case\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "# from bokeh.plotting import figure, show\n",
    "# from bokeh.io import output_notebook\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "# output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865550c3-2796-4fad-9905-62e64a844ccd",
   "metadata": {},
   "source": [
    "# Scientific pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd9e8b0b-af97-4270-af57-f8a0a405763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import scipy\n",
    "from tqdm.notebook import tqdm # FOR FANCY GREEN BAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba7555b-6103-4208-b821-78f83f126afb",
   "metadata": {},
   "source": [
    "# NLP pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5802194-79f7-41ce-bb08-ac3d539e74ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dcf078-461a-45d9-9206-1cf9d0516249",
   "metadata": {},
   "source": [
    "# LangChain  pkgs\n",
    "\n",
    "### Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a2c97d-5946-423e-bc71-e04dc647c958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import RedditPostsLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3528c9-173b-482e-adb7-bde8dfa3d6f6",
   "metadata": {},
   "source": [
    "### Doc spitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99de4d4d-9b82-4e26-8d93-457ec2ed313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d056ec-21ec-454c-abf4-3e1fb790aa2f",
   "metadata": {},
   "source": [
    "# Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74ad15af-b208-4c8a-8eaf-7a567263bd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mxbai-embed-large:latest', 'deepseek-r1:8b', 'nomic-embed-text:latest', 'llama3.2:latest']\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "# ollama.base_url = \"http://192.168.56.1:11434\"\n",
    "# ollama.base_url = os.getenv(\"OLLAMA_API_URL\",\"http://localhost:11434\")\n",
    "# ollama.base_url = \"http://host.docker.internal:11434\"  # or \"http://localhost:11434\" if installed locally\n",
    "\n",
    "models = ollama.list()\n",
    "print([model['model'] for model in models['models']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd5c1d0-a5d4-4d84-85fc-2199c58ffdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the Republic of the Congo is Brazzaville. However, the Democratic Republic of the Congo (formerly known as Zaire) has its capital in Kinshasa. It's worth noting that there are two separate countries with similar names: the Republic of the Congo and the Democratic Republic of the Congo.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the capital of Congo?\"\n",
    "model = \"llama3.2\"#\"deepseek-r1:8b\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=model,\n",
    "    messages=[{\"role\":\"user\",\"content\":prompt}]\n",
    ")\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2577fb41-8d92-4d3e-bc8f-60646e565915",
   "metadata": {},
   "source": [
    "# Special pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35b42c11-409d-4101-9bc1-40af4c926cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime # DateTime\n",
    "# import drawdata\n",
    "# import anywidget\n",
    "# import networkx as nx\n",
    "# import anytree\n",
    "# from faker import Faker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4726cec6-5009-4717-a2cb-c9f48cb96ba7",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f957be6-b7d0-4400-9607-01895cecba9f",
   "metadata": {},
   "source": [
    "## PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8bd6db07-56ed-4777-b9a1-afb586adcd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"data/GeoAI.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b48d62db-25bd-4bef-8075-5df995818685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb102708-b4b0-42d9-8b49-bbea721e599d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'PyPDF', 'creator': 'Springer', 'creationdate': '2023-01-02T18:26:57+05:30', 'author': 'Simon Scheider', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'crossmarkdomainexclusive': 'true', 'crossmarkmajorversiondate': '2010-04-23', 'moddate': '2023-05-29T07:00:47+05:30', 'subject': 'KI - Künstliche Intelligenz, https://doi.org/10.1007/s13218-022-00797-z', 'title': 'GeoAI', 'doi': '10.1007/s13218-022-00797-z', 'robots': 'noindex', 'source': 'data/GeoAI.pdf', 'total_pages': 5, 'page': 0, 'page_label': '5'}, page_content='Vol.:(0123456789)1 3\\nKI - Künstliche Intelligenz (2023) 37:5–9 \\nhttps://doi.org/10.1007/s13218-022-00797-z\\nEDITORIAL\\nGeoAI\\nSimon\\xa0Scheider1\\xa0· Kai‑Florian\\xa0Richter2\\nPublished online: 20 January 2023 \\n© The Author(s), under exclusive licence to Springer-Verlag GmbH Germany and Gesellschaft für Informatik e.V. 2023\\nResearch in artificial intelligence (AI), geography, and \\ngeographic information science (GIScience) has had multiple \\nfruitful points of contact during the past decades. More than \\n30 years ago, [5 , 21, 26] suggested how AI methods could \\nbe used for spatial modelling and geographic problem-\\nsolving, including neural nets for regression modelling, \\nspatial optimisation, spatial pattern recognition, and spatial \\nsimulation, but also the use of spatial knowledge bases \\nand expert systems [ 20]. Thus, from the very beginning \\nof geoAI 1, both data-driven (machine learning (ML), \\noptimisation, and simulation) methods, as well as theory \\ndevelopment was taken into focus. While some geographers \\nat the time complained about an apparent lack of theory \\nin AI, [5 ] argued that a cognitive and computational \\nengineering approach might have the capacity to advance \\ntheory as well as method development in geography based \\non testing formal and computational representations of \\nqualitative as well as quantitative concepts. And indeed, \\nsuch an approach towards geography and geographic \\ninformation bore fruits. For example, spatial simulation \\nmodels formed the basis of urban modelling and complexity \\nscience [3], spatial pattern detection, ML classification and \\nregression have been adopted in geographic analysis [14, \\n17], and natural language processing (NLP) techniques \\nfor georeferencing texts [ 10]. Furthermore, knowledge \\nrepresentation and reasoning methods in AI have inspired \\nthe development of spatial calculi for spatial reasoning [4, 6, \\n30], as well as geospatial knowledge models in the Semantic \\nWeb [7], ontologies of space [8], and, more recently, spatial \\nknowledge graphs [11]. These different strands of work \\nhave resulted in new geographic information retrieval (GIR) \\nmethods [22], digital twins of cities [2], as well as progress \\nin human-computer interaction, orientation, and wayfinding \\n[23].\\nIn recent times, subsymbolic AI methods, such as deep \\nlearning and representation learning, have enabled an \\nincrease in quality and scalability of data processing methods \\nin remote sensing [29], geographic information retrieval [27] \\nas well as geographic question-answering (GeoQA) [15, 16]. \\nAt the same time, knowledge about geographic information \\nprocesses has become an indispensable resource for AI \\nitself. Such knowledge is needed not only for modelling \\ngeographic information concepts [12, 25], and for making \\nopaque models transparent [31], but also for understanding \\nwhat kind of intelligence is needed to refer to place [ 9, \\n13, 18] and to handle geographic space [19, 24]. Among \\nothers, researchers are currently working on formal theories \\nof space [1] and geographic quantities [28]. Understood in \\nthis broader sense, namely as the intelligence needed to \\nhandle geographic information, geoAI has the potential to \\nfundamentally improve the way geographic information can \\nbe processed and interpreted by both humans and machines.\\nIn this special issue, we look at research investigating \\nthe kind of knowledge needed to account for geography and \\nspace with(in) intelligent machines.\\n1  Content\\n1.1  Overview and\\xa0Discussion\\nOur overview article further outlines the developments \\nsketched above and provides a survey of current areas of \\nresearch within geoAI, in particular, geoAI for handling \\nvarious information sources, interaction with geoAI systems, \\nand the question of whether explicit spatial models, i.e., \\nmodels that incorporate some a-priori spatial knowledge, \\nare needed in geoAI.\\n * Simon Scheider \\n s.scheider@uu.nl\\n Kai-Florian Richter \\n kai-florian.richter@umu.se\\n1 Department of\\xa0Human Geography and\\xa0Spatial Planning, \\nUtrecht University, Princetonlaan 8a, 3584\\xa0CB\\xa0Utrecht, \\nThe\\xa0Netherlands\\n2 Department of\\xa0Computing Science, Umeå University, \\n901\\xa087\\xa0Umeå, Sweden\\n1 We use the term loosely here, but see also the definitions in our \\noverview and discussion paper in this issue.')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = pages[0]\n",
    "page # First Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8cd850d7-ed14-4a6c-8ab4-4391528d5fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'PyPDF',\n",
       " 'creator': 'Springer',\n",
       " 'creationdate': '2023-01-02T18:26:57+05:30',\n",
       " 'author': 'Simon Scheider',\n",
       " 'crossmarkdomains[1]': 'springer.com',\n",
       " 'crossmarkdomains[2]': 'springerlink.com',\n",
       " 'crossmarkdomainexclusive': 'true',\n",
       " 'crossmarkmajorversiondate': '2010-04-23',\n",
       " 'moddate': '2023-05-29T07:00:47+05:30',\n",
       " 'subject': 'KI - Künstliche Intelligenz, https://doi.org/10.1007/s13218-022-00797-z',\n",
       " 'title': 'GeoAI',\n",
       " 'doi': '10.1007/s13218-022-00797-z',\n",
       " 'robots': 'noindex',\n",
       " 'source': 'data/GeoAI.pdf',\n",
       " 'total_pages': 5,\n",
       " 'page': 0,\n",
       " 'page_label': '5'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "080979f3-d09c-4389-82ad-0ccaf0ff699c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vol.:(0123456789)1 3\\nKI - Künstliche Intelligenz (2023) 37:5–9 \\nhttps://doi.org/10.1007/s13218-022-00797-z\\nEDITORIAL\\nGeoAI\\nSimon\\xa0Scheider1\\xa0· Kai‑Florian\\xa0Richter2\\nPublished online: 20 January 2023 \\n© The Author(s), under exclusive licence to Springer-Verlag GmbH Germany and Gesellschaft für Informatik e.V. 2023\\nResearch in artificial intelligence (AI), geography, and \\ngeographic information science (GIScience) has had multiple \\nfruitful points of contact during the past decades. More than \\n30 yea'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.page_content[:500] # first 500 charecters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f5b55e-a7e5-469e-b7da-6d98645a79c0",
   "metadata": {},
   "source": [
    "## YouTube\n",
    "\n",
    "- https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.generic.GenericLoader.html\n",
    "- https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.youtube.YoutubeLoader.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f5d24b72-d524-4993-956d-b73e5370fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import GenericLoader\n",
    "from langchain_community.document_loaders.blob_loaders import FileSystemBlobLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969956d3-6579-45d4-b47d-d96211466374",
   "metadata": {},
   "source": [
    "## URLs\n",
    "\n",
    "- https://python.langchain.com/docs/integrations/document_loaders/web_base/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f8284aea-e3d7-474c-8032-5228433ed0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Black-crowned_barwing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "82355687-1eca-46a0-9454-15b94899c94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://en.wikipedia.org/wiki/Black-crowned_barwing', 'title': 'Black-crowned barwing - Wikipedia', 'language': 'en'}, page_content='\\n\\n\\n\\nBlack-crowned barwing - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nTaxonomy\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nDescription\\n\\n\\n\\n\\nToggle Description subsection\\n\\n\\n\\n\\n\\n2.1\\nMeasurements\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nDistribution and habitat\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nBehaviour\\n\\n\\n\\n\\nToggle Behaviour subsection\\n\\n\\n\\n\\n\\n4.1\\nVocalisation\\n\\n\\n\\n\\n\\n\\n\\n\\n4.2\\nDiet\\n\\n\\n\\n\\n\\n\\n\\n\\n4.3\\nBreeding\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nConservation status\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n7\\nExternal links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nBlack-crowned barwing\\n\\n\\n\\n16 languages\\n\\n\\n\\n\\nБългарскиCatalàCebuanoDiné bizaadEspañolEuskaraفارسیFrançaisMagyarNederlandsPolskiPortuguêsSvenskaУкраїнськаTiếng Việt中文\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikispeciesWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nSpecies of bird\\n\\n\\n\\n\\nBlack-crowned barwing\\n\\n\\n\\n\\n\\nConservation status\\n\\n\\nNear Threatened \\xa0(IUCN 3.1)[1]\\n\\n\\nScientific classification \\n\\n\\nDomain:\\n\\nEukaryota\\n\\n\\nKingdom:\\n\\nAnimalia\\n\\n\\nPhylum:\\n\\nChordata\\n\\n\\nClass:\\n\\nAves\\n\\n\\nOrder:\\n\\nPasseriformes\\n\\n\\nFamily:\\n\\nLeiothrichidae\\n\\n\\nGenus:\\n\\nActinodura\\n\\n\\nSpecies:\\n\\nA.\\xa0sodangorum\\n\\n\\nBinomial name\\n\\n\\nActinodura sodangorumEames, JC, Trai Trong Le, Nguyen Cu & Eve, 1998\\n\\n\\nThe black-crowned barwing (Actinodura sodangorum) is a non-migratory bird from Indochina in the family Leiothrichidae (laughingthrushes and allies).[2] The genus name Actinodura is from Ancient Greek meaning \"ray-like tail\" (actinodes and ura), while the specific epithet sodangorum is from the Xo Dang tribe which lives in Ngoc Linh and other areas in Vietnam, Cambodia and Laos where black-crowned barwings are found.[3][4]\\n\\n\\nTaxonomy[edit]\\nThe first black-crowned barwing sighting was reported in April 1996 at Ngọc Linh, Vietnam.[4] Prior to survey, the central highland area of Vietnam was mostly ornithologically undiscovered. Many observations were made by Jonathon Charles Eames and Roland Eve, but it took until 17 March 1998 to trap a male bird.[4] An official species description was later published in 1999.[4]\\nBlack-crowned barwings consist of a monotypic group; having no other discovered subspecies.[4] They were quickly classified into Actinodura since they are very similar to Actinodura ramsayi in appearance.[5] Three plumage differences set them apart; the lores are black, the posterior is darker olive-brown, and the tail feathers are darker with narrower white tips.[3]\\n\\nDescription[edit]\\nThe black-crowned barwing is the only bird in the genus Actinodura to have a black crown.[3] The transverse barring on the wings (wingbars) and the crest are characteristic of the genus.[3] The sexes are similar in appearance.[4] It has a grey head and nape, black crown and lore (space between eye and beak), white eye rings, dark brown irises, and dark beak with a flesh coloured tip.[4] The throat is streaked with black-brown on a base of rufous-orange that matches the breast and belly area.[4] The posterior parts of the body (mantle, back, rump, and uppertail coverts) are olive-brown with indistinct dark bars.[3][4] The wings have fine bars on the scapulars (upper wing section) and black-brown with chestnut or orange-buff bars on most of the flight feathers (primaries and secondaries).[4] Their long tail is graduated chestnut with white tips and broad black bars.[4]\\n\\nMeasurements[edit]\\nThe lengths are approximately:[3]\\n\\nUpper beak (culmen) = 17.5\\xa0mm (0.69\\xa0in)\\nLeg length (starting from under the knees) = 31\\xa0mm (1.2\\xa0in)\\nSingle wing length (measured from chord to mass) = 89\\xa0mm (3.5\\xa0in)\\nTail-length = 133\\xa0mm (5.2\\xa0in)\\nDistribution and habitat[edit]\\nThey are resident at three locations in Laos and at seven locations in Vietnam. They are also found in Important Bird and Biodiversity Areas (IBA) including the DakChung Plateau, Lo Xo Pass, and Ngoc Linh.[2]\\nTheir natural habitats are subtropical or tropical moist montane forest, subtropical or tropical high-altitude shrubland, subtropical or tropical high-altitude grassland, and plantations.[2] Although they use degraded/cleared forests,[3] they are mostly found in secondary growth or evergreen forests.[6]\\nTheir elevation maximum was at 2,400\\xa0m (7,900\\xa0ft), with observers noting fewer sightings above 2,200\\xa0m (7,200\\xa0ft).[3] The minimum elevation range could not be determined properly since the site contained loss of forest habitat below 1,500\\xa0m (4,900\\xa0ft), though there were sightings at 1,000\\xa0m (3,300\\xa0ft).[3]\\n\\nBehaviour[edit]\\nSightings have been either of single birds or in pairs.[6]\\n\\nVocalisation[edit]\\nMost observations were of singing birds since they are easily identified through song and were responsive to playbacks, which was a commonly used technique.[3] They call the most in early morning, decreasing through the day, which could be caused by rainfall reducing their activity.[3]\\nThey have two distinctive calls:\\n\\nOne of the calls begins with a male or female giving two or three \"wa\" wails that sound cat-like with the first note always weakest and the second note stronger.[3] After 5–20 calls from the initiator, the second bird responds with five or six short notes with overall same length and pitch.[3]\\nThe other call lasts for as long as the first bird continues and includes antiphonal duets, where males and females respond to each other differently.[3] Pairs were also spotted sitting side-by-side mutually preening between their calls.[3]\\nDiet[edit]\\nTheir diet is not well known, but they are suspected to be insectivores that also eat vegetation.[7] The bird is often seen foraging alone or with a partner around the smaller branches of tree canopy, trunk, and along larger moss-covered branches.[3][4]\\n\\nBreeding[edit]\\nMates are first attracted through calling, then move to small branches in shrubs while perching close or against each other.[8] The male displays by raising his crest and half-fanning his feathers while the female opens her wings less frequently and leans steeply over her perch.[8] They preen each other briefly and rapidly with light pecking, while switching positions.[8] Instances of copulating or almost copulating involved the birds swinging full circle around a branch where their tail-bases would briefly touch while moving downwards.[8] This behaviour is not known in barwings, but is more common in babblers (family Timaliidae).[8]\\nGeneration lengths are around 5.5 years.[6]\\nEggs and nest are undescribed.[4]\\n\\nConservation status[edit]\\nIt is threatened by habitat loss[6] and is considered Near Threatened on the IUCN Red List.[1]\\n\\nReferences[edit]\\n\\n\\n^ a b BirdLife International (2020). \"Actinodura sodangorum\". IUCN Red List of Threatened Species. 2020: e.T22716552A177885722. doi:10.2305/IUCN.UK.2020-3.RLTS.T22716552A177885722.en. Retrieved 11 November 2021.\\n\\n^ a b c \"Black-crowned Barwing (Actinodura sodangorum) – BirdLife species factsheet\". datazone.birdlife.org. Retrieved 5 October 2018.\\n\\n^ a b c d e f g h i j k l m n o p Eames, Jonathan C.; Trai, Le Trong; Cu, Nguyen; Eve, Roland (January 1999). \"New species of Barwing Actinodura (Passeriformes: Sylviinae: Timaliini) from the Western Highlands of Vietnam\". Ibis. 141 (1): 1–10. doi:10.1111/j.1474-919x.1999.tb04257.x. ISSN\\xa00019-1019.\\n\\n^ a b c d e f g h i j k l m Brewer, David (26 January 2018). Birds New to Science: Fifty Years of Avian Discoveries. Bloomsbury Publishing. ISBN\\xa09781472945891.\\n\\n^ Dong, Feng; Wu, Fei; Liu, Lu-ming; Yang, Xiao-jun (2010). \"Molecular phylogeny of the Barwings (Aves: Timaliidae: Actinodura), a paraphyletic group, and its taxonomic implications\" (PDF). Zoological Studies. 49 (5): 703–709. CiteSeerX\\xa010.1.1.651.9896.\\n\\n^ a b c d \"IUCN Red List maps\". Explore and discover Red List species ranges and observations. Retrieved 6 October 2018.\\n\\n^ Collar, Nigel; Robson, Craig; De Juana, Eduardo (2020). Del Hoyo, Josep; Elliott, Andrew; Sargatal, Jordi; Christie, David; De Juana, Eduardo (eds.). \"Black-crowned Barwing (Actinodura sodangorum)\". hbw.com. doi:10.2173/bow.bkcbar1.01. Retrieved 9 October 2018.\\n\\n^ a b c d e del Hoyo, J.; Collar, N. J. (2011). \"Acrobatic copulatory display in the Black-crowned Barwing Actinodura sodangorum\" (PDF). Forktail. 27. Oriental Bird Club: 112–113. Retrieved 21 May 2025.\\n\\n\\nExternal links[edit]\\nCornell Lab Macaulay Library Bird Calls and Images\\nxeno-canto Bird Calls\\nExternal Anatomy at Ornithology.com\\nTaxon identifiersActinodura sodangorum\\nWikidata: Q2823625\\nWikispecies: Actinodura sodangorum\\nADW: Actinodura_sodangorum\\nARKive: actinodura-sodangorum\\nAvibase: E5AD68C4DF5205FF\\nBirdLife: 22716552\\nBOW: bkcbar1\\nCoL: 6524M\\neBird: bkcbar1\\nGBIF: 5788984\\niNaturalist: 72457\\nITIS: 916132\\nIUCN: 22716552\\nNCBI: 2944897\\nOpen Tree of Life: 3598425\\nPlazi: 614031F1-D468-A452-631A-7C18E41D99F8\\nXeno-canto: Actinodura-sodangorum\\nZooBank: BB105B31-DE6C-49CD-A232-5D910AD052A8\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Black-crowned_barwing&oldid=1291475583\"\\nCategories: IUCN Red List near threatened speciesActinoduraBirds described in 1999Birds of LaosBirds of VietnamHidden categories: Articles with short descriptionShort description matches WikidataUse dmy dates from October 2023Articles with \\'species\\' microformatsArticles containing Ancient Greek (to 1453)-language textTaxonomy articles created by Polbot\\n\\n\\n\\n\\n\\n\\n This page was last edited on 21 May 2025, at 13:29\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nBlack-crowned barwing\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n16 languages\\n\\n\\nAdd topic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = docs = loader.load()\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e441638-3c55-43bb-a70b-28c9acf1c835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bb2d68b8-5250-443c-be96-ead4bd86ac55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(page[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f0875a80-1b2e-4696-982d-1e9f62626e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(page[0], 'html.parser')\n",
    "# regex = re.compile('.*\\n*')\n",
    "# results = soup.find_all('p', {'class':regex})\n",
    "# reviews = [result.text for result in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d105768-60c4-4d6d-be1a-4a7013ac7206",
   "metadata": {},
   "source": [
    "## Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "02e2f3c7-a503-45ef-a797-daa59095ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import RedditPostsLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3633ce5b-aff5-4c86-b544-6d34b0c1fda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a817c89-1a47-4fed-82b2-34dd3fb09814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86085524-ca84-46af-92fe-40386629e8b7",
   "metadata": {},
   "source": [
    "# Document Chunking/Splitting\n",
    "\n",
    "- https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f1413623-e445-4aca-b57c-2b239a712a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f146235b-ad36-47df-941e-0e3552887be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE =20\n",
    "CHUNK_OVERLAP = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8adae434-13b1-440f-aa0a-ac4b52adb962",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5dd46573-2b0b-4697-82ed-9f41f1ccfcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'abcdefghijklmnopqrstuvwxyzabcdefg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6a7be404-98df-43e7-890e-55bfc4feca74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrst', 'rstuvwxyzabcdefg']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "043f62e4-6a81-40ef-b43d-79077acc3522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyzabcdefg']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9bf85c45-22e2-427b-b3db-6dc53b5355e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4f9a0ea4-08fc-4b90-9f46-135555e4470b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j', 'j k l m n o p q r s', 's t u v w x y z']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0af4b901-3b4f-404f-b7f7-08fdac60dde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m n o p q r s t u v w x y z']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5ce03e49-150f-452e-b8b2-fd3eeaa86fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Default separator is \\nbut in this case we want single space ' '\n",
    "c_splitter2 = CharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    separator = ' '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "97694af8-8fe9-464a-880c-70548e971e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j', 'i j k l m n o p q r', 'q r s t u v w x y z']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter2.split_text(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4463596f-de2d-41ed-a741-4fe7d9ec3825",
   "metadata": {},
   "source": [
    "### `RecursiveCharacterTextSplitter` is recommended for generic text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4bb994ea-8cfc-475e-a323-84c7281d4a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\"\n",
    "\n",
    "len(real_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7cdba63e-574d-48e9-bd20-01f2109f2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] # rankwise --> double new line, single new line, space, empty string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ed9e4859-9c77-4f0d-8916-bc80c2eb4c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
       " 'have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(real_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "99b592bc-6db9-444e-8e70-61b39bccdd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(real_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d7e856d6-2553-4bac-96b5-b70e760d97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\.\", \" \", \"\"] # rankwise --> double new line, single new line, inbetween sent, space, empty string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "99afa6f0-c18a-4214-8b2e-64c9fb4eeb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(real_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ed457520-dd3c-42b8-8ec6-b1ea4dc888d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]  # rankwise --> double new line, single new line, regex(inbetween sent), space, empty string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fea1200a-3868-49e0-88aa-d6096b672a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(real_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783b14c0-9cbd-4a72-a1c0-2fcad2159d91",
   "metadata": {},
   "source": [
    "## PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d8cb1db1-760b-4f87-adf2-88a8891d8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"data/GeoAI.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ca364bce-9231-40e2-8400-61acd6474137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bf2ecc9d-a571-49e3-bfa9-422873f48d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len # default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9336878a-1749-458a-b753-ccaf19df406e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = text_splitter.split_documents(pages)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "33844191-b5bf-4f2b-acaa-4a0176ab66e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'PyPDF', 'creator': 'Springer', 'creationdate': '2023-01-02T18:26:57+05:30', 'author': 'Simon Scheider', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'crossmarkdomainexclusive': 'true', 'crossmarkmajorversiondate': '2010-04-23', 'moddate': '2023-05-29T07:00:47+05:30', 'subject': 'KI - Künstliche Intelligenz, https://doi.org/10.1007/s13218-022-00797-z', 'title': 'GeoAI', 'doi': '10.1007/s13218-022-00797-z', 'robots': 'noindex', 'source': 'data/GeoAI.pdf', 'total_pages': 5, 'page': 0, 'page_label': '5'}, page_content='Vol.:(0123456789)1 3\\nKI - Künstliche Intelligenz (2023) 37:5–9 \\nhttps://doi.org/10.1007/s13218-022-00797-z\\nEDITORIAL\\nGeoAI\\nSimon\\xa0Scheider1\\xa0· Kai‑Florian\\xa0Richter2\\nPublished online: 20 January 2023 \\n© The Author(s), under exclusive licence to Springer-Verlag GmbH Germany and Gesellschaft für Informatik e.V. 2023\\nResearch in artificial intelligence (AI), geography, and \\ngeographic information science (GIScience) has had multiple \\nfruitful points of contact during the past decades. More than \\n30 years ago, [5 , 21, 26] suggested how AI methods could \\nbe used for spatial modelling and geographic problem-\\nsolving, including neural nets for regression modelling, \\nspatial optimisation, spatial pattern recognition, and spatial \\nsimulation, but also the use of spatial knowledge bases \\nand expert systems [ 20]. Thus, from the very beginning \\nof geoAI 1, both data-driven (machine learning (ML), \\noptimisation, and simulation) methods, as well as theory')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a6fca6-3de4-4ea8-bcf1-aa9547ceac4f",
   "metadata": {},
   "source": [
    "## Token splitting\n",
    "\n",
    "We can also split on token count explicity, if we want. \n",
    "\n",
    "- This can be useful because LLMs often have context windows with designated token counts limit.\n",
    "\n",
    "- Tokens are often ~4 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3771458b-f540-4c5e-b556-8e1c5d700710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "57062ac2-8de0-4711-ba47-35f36f6d7497",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "92ba7a53-7ecb-466e-9bba-ed2b9151a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "pangram = \"The quick brown fox jumps over the lazy dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b0b60045-1b00-43fa-8fbe-17dae10c2834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', ' quick', ' brown', ' fox', ' jumps', ' over', ' the', ' lazy', ' dog']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter.split_text(pangram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4e431c7c-ca52-46be-9596-244e9447e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter5 = TokenTextSplitter(chunk_size=5, chunk_overlap=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "24b124af-3a4a-4e03-891a-8dab67d1b27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The quick brown fox jumps', ' jumps over the lazy dog']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter5.split_text(pangram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "18c84e92-c581-4894-a980-67759e01e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter10 = TokenTextSplitter(chunk_size=10, chunk_overlap=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e2be37da-af2a-48f8-ace3-8eac9c970b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = text_splitter10.split_documents(pages)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a4be126a-dc92-4d3c-924b-235858293c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'PyPDF', 'creator': 'Springer', 'creationdate': '2023-01-02T18:26:57+05:30', 'author': 'Simon Scheider', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'crossmarkdomainexclusive': 'true', 'crossmarkmajorversiondate': '2010-04-23', 'moddate': '2023-05-29T07:00:47+05:30', 'subject': 'KI - Künstliche Intelligenz, https://doi.org/10.1007/s13218-022-00797-z', 'title': 'GeoAI', 'doi': '10.1007/s13218-022-00797-z', 'robots': 'noindex', 'source': 'data/GeoAI.pdf', 'total_pages': 5, 'page': 0, 'page_label': '5'}, page_content='Vol.:(0123456789)1')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4197db-e70e-43c7-add0-99b942fbeabc",
   "metadata": {},
   "source": [
    "## Context aware splitting\n",
    "\n",
    "Chunking aims to keep text with common context together.\n",
    "\n",
    "A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
    "\n",
    "We can use MarkdownHeaderTextSplitter to preserve header metadata in our chunks, as show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8522498d-c5c1-4110-b80b-29607cd483a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "86494ae9-3ca3-4345-83fe-3261177f11e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1a253857-d1e8-44c9-9045-7738afacfaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4d1654d4-3210-42d1-944d-0b8e165cdc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c6e4def7-1bef-486d-ba87-f6d47cffbc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}, page_content='Hi this is Jim  \\nHi this is Joe'),\n",
       " Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'}, page_content='Hi this is Lance'),\n",
       " Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 2'}, page_content='Hi this is Molly')]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2e666428-2202-42e8-b5f5-7a054606e72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi this is Jim  \\nHi this is Joe'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9cdbce18-5f86-4e09-b3c4-49c69c0293ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi this is Lance'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "04098d6b-e800-49fc-98a6-6ff7651e09e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi this is Molly'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[2].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6cfe67-48b6-4e37-96af-5276203b190b",
   "metadata": {},
   "source": [
    "# Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4bad8629-b9c6-43b5-902c-99b2e2e746f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    PyPDFLoader(\"data/Julia_CV.pdf\"),\n",
    "    PyPDFLoader(\"data/Mohamad_AL.pdf\"),\n",
    "    PyPDFLoader(\"data/Julia_CV.pdf\"),\n",
    "    PyPDFLoader(\"data/Jiaxin_Lu_CV.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e42c66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ec03e25-fa9f-4a61-be70-a8c0ec815a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d3af9fb-2687-4787-b92b-4f77feac8dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55707289-b1f1-4ae9-a729-70531fe3bf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc344ba7-d99f-48d8-99a8-9874acd3849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\") # mxbai-embed-large, llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cab4ca87-135b-4791-9921-519c8482f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i love dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "34c988a0-ff4d-4fa1-9507-0a6593abe4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embeddings.embed_query(sentence1)\n",
    "embedding2 = embeddings.embed_query(sentence2)\n",
    "embedding3 = embeddings.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c3fbe96c-66d9-4ece-8e4b-288a7e18cf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9133644795093009"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50d1607c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36676847492935283"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33570422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3743773623914262"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6e75b9",
   "metadata": {},
   "source": [
    "# Vectorstores\n",
    "- https://python.langchain.com/docs/integrations/vectorstores/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a9df4054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "persist_directory = 'data/chroma4/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "938b81a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./data/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "63e49c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7056c73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cad1bb",
   "metadata": {},
   "source": [
    "# Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "201b9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = \"What are locations in the document?\"\n",
    "\n",
    "docs = vectordb.similarity_search(Q, k=5) # K = nu of docs\n",
    "\n",
    "docs_ss = vectordb.similarity_search(Q,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e6a13b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- EMBO Conference: \"Telomere Function and Evolution in Health and \n",
      "Disease\" – Troia, Portugal | Poster and Microtalk \n",
      "- La Ligue Contre le Cancer Day – Paris, France \n",
      "- Internal Seminars at the CRCM – Presented annually throughout my PhD \n",
      "2021 & 2022 \n",
      "26 Sep- 01 Oct 2022 \n",
      "4th of February 2023 \n",
      "Publications \n",
      " Al hajj et al, 2024 “Rap1-dependent replication stress at telomeres induces relocalization  \n",
      "to the nuclear pore complexes” Online HAL preprint  \n",
      "• Sports nutrition\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fe00c5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bacterial and yeast transformation, western and southern blot, gel \n",
      "electrophoresis, immunoprecipitation, DNA extraction, purification and \n",
      "quantification (Qubit, nanodrop), spheroplast separation, radioactivity \n",
      "manipulation, DAPI staining, silver sta ining, kinetics of senescence, cell \n",
      "synchronization, microscopy (light, inverted, fluorescent, yeast \n",
      "micromanipulator)  \n",
      "• Analyzed large data sets using excel, GraphPad prism, ImageJ and persus.  \n",
      " \n",
      " \n",
      "January 2021- Dec 2024\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b0015db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the nuclear pore complexes” Online HAL preprint  \n",
      "• Sports nutrition \n",
      "• Calisthenics and endurance sports \n",
      "• Reading \n",
      "• Traveling \n",
      "• Artificial intelligence \n",
      " \n",
      " Skills \n",
      "• Genetics \n",
      "• Molecular biology \n",
      "• Cancer biology \n",
      "• Data analysis \n",
      "● Mentoring \n",
      "● Critical thinking \n",
      "● Adaptability \n",
      "● Autonomous \n",
      "● Presentation skills \n",
      "● Project managment \n",
      "● Team work \n",
      "● Commitment\n"
     ]
    }
   ],
   "source": [
    "print(docs[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "34a4d83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier OOD Detection for Partial Matching”, ICLR 2025, [arxiv:2210.10374]\n",
      "6. Jiaxin Lu ∗, Zetian Jiang∗, Tianzhe Wang and Junchi Yan, “M3C: A Framework towards Convergent, Flexible, and\n",
      "Unsupervised Learning of Mixture Graph Matching and Clustering”, ICLR 2024, [arxiv:2310.18444]\n",
      "*, †denotes equal contribution\n",
      "Research Experience\n",
      "Adobe San Jose, U.S.A\n",
      "Reserach Intern, Advised by Dr. Yi Zhou May 20224 - present\n",
      "•Generative Human-object interaction\n"
     ]
    }
   ],
   "source": [
    "print(docs[4].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0420955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the nuclear pore complexes” Online HAL preprint  \n",
      "• Sports nutrition \n",
      "• Calisthenics and endurance sports \n",
      "• Reading \n",
      "• Traveling \n",
      "• Artificial intelligence \n",
      " \n",
      " Skills \n",
      "• Genetics \n",
      "• Molecular biology \n",
      "• Cancer biology \n",
      "• Data analysis \n",
      "● Mentoring \n",
      "● Critical thinking \n",
      "● Adaptability \n",
      "● Autonomous \n",
      "● Presentation skills \n",
      "● Project managment \n",
      "● Team work \n",
      "● Commitment\n"
     ]
    }
   ],
   "source": [
    "print(docs_ss[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff77c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8a0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99a30959",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  save this so we can use it later!\n",
    "# vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2bfff627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'AL HAJJ Mohamad', 'creationdate': '2025-04-01T13:19:31+02:00', 'creator': 'Microsoft® Word pour Microsoft\\xa0365', 'moddate': '2025-04-01T13:19:31+02:00', 'page': 0, 'page_label': '1', 'producer': 'Microsoft® Word pour Microsoft\\xa0365', 'source': 'data/Mohamad_AL.pdf', 'total_pages': 1}\n",
      "{'author': 'AL HAJJ Mohamad', 'creationdate': '2025-04-01T13:19:31+02:00', 'creator': 'Microsoft® Word pour Microsoft\\xa0365', 'moddate': '2025-04-01T13:19:31+02:00', 'page': 0, 'page_label': '1', 'producer': 'Microsoft® Word pour Microsoft\\xa0365', 'source': 'data/Mohamad_AL.pdf', 'total_pages': 1}\n",
      "{'author': 'AL HAJJ Mohamad', 'creationdate': '2025-04-01T13:19:31+02:00', 'creator': 'Microsoft® Word pour Microsoft\\xa0365', 'moddate': '2025-04-01T13:19:31+02:00', 'page': 0, 'page_label': '1', 'producer': 'Microsoft® Word pour Microsoft\\xa0365', 'source': 'data/Mohamad_AL.pdf', 'total_pages': 1}\n",
      "{'author': 'AL HAJJ Mohamad', 'creationdate': '2025-04-01T13:19:31+02:00', 'creator': 'Microsoft® Word pour Microsoft\\xa0365', 'moddate': '2025-04-01T13:19:31+02:00', 'page': 0, 'page_label': '1', 'producer': 'Microsoft® Word pour Microsoft\\xa0365', 'source': 'data/Mohamad_AL.pdf', 'total_pages': 1}\n",
      "{'author': '', 'creationdate': '2025-02-03T23:46:54+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-02-03T23:46:54+00:00', 'page': 0, 'page_label': '1', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'data/Jiaxin_Lu_CV.pdf', 'subject': '', 'title': '', 'total_pages': 2, 'trapped': '/False'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a62ea1",
   "metadata": {},
   "source": [
    "# Rretrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "56aa3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "persist_directory = 'data/chroma3/'\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\") # mxbai-embed-large, llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d1ac4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "045a7daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ff0cf7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "63b5656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldb = Chroma.from_texts(texts, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "733c6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e9c89f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='b79570c6-8016-4ee5-802c-266ed1edfdd7', metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(id='7359d55c-9138-4779-b21c-9aa7bb0cf12c', metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.similarity_search(question, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8cc1ac65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='b79570c6-8016-4ee5-802c-266ed1edfdd7', metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(id='7359d55c-9138-4779-b21c-9aa7bb0cf12c', metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.')]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f892eabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "20837b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "persist_directory = 'data/chromaAI/'\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\") # mxbai-embed-large, llama3.2\n",
    "\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "56a770c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4f4219e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "603113f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "031acb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader(\"data/GeoAI.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e7a01da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embeddings)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "446251e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automatically generating large natural language corpora \n",
      "of landscape descriptions using small curated corpora as \n",
      "seed in their article Generating large corpora of landscape \n",
      "relevant natural language using actively crowdsourced \n",
      "landscape descriptions and sentence-transformers. As is \n",
      "common practice in NLP now, source and target corpora \n",
      "get vectorized, and then cosine similarity is used to identify \n",
      "the text most likely to be relevant for the target corpora. \n",
      "The authors demonstrate the benefits of using sentence \n",
      "transformers over a purely lexical approach; TF*IDF in this \n",
      "case.\n",
      "An important aspect of geographic information retrieval \n",
      "and question answering is identifying what (types of) \n",
      "geographic information the user is referring to. In their paper \n",
      "Automated interpretation of place descriptions: determining \n",
      "entity types for querying OSM, Madiha Yousaf, Tobias \n",
      "Schwartz, and Diedrich Wolter present an approach that \n",
      "given a natural language input (a query) provides a ranked \n",
      "list of likely OpenStreetMap (OSM) tags that represent the \n",
      "entities referred to in the input. Noun-to-tag and tag-to-tag \n",
      "similarity is used to improve existing semantic similarity \n",
      "measures, such as word2vec or BERT, as demonstrated in \n",
      "an extensive evaluation.\n",
      "1.3  Project Report\n",
      "In the article UR Walking—Indoor navigation for research \n",
      "and daily use, Bernd Ludwig, Gregor Donabauer, Dominik \n",
      "Ramsauer and Karema Al Subari report about results of\n"
     ]
    }
   ],
   "source": [
    "question = \"What are authors of this document?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "print(docs_svm[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "09329150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automatically generating large natural language corpora \n",
      "of landscape descriptions using small curated corpora as \n",
      "seed in their article Generating large corpora of landscape \n",
      "relevant natural language using actively crowdsourced \n",
      "landscape descriptions and sentence-transformers. As is \n",
      "common practice in NLP now, source and target corpora \n",
      "get vectorized, and then cosine similarity is used to identify \n",
      "the text most likely to be relevant for the target corpora. \n",
      "The authors demonstrate the benefits of using sentence \n",
      "transformers over a purely lexical approach; TF*IDF in this \n",
      "case.\n",
      "An important aspect of geographic information retrieval \n",
      "and question answering is identifying what (types of) \n",
      "geographic information the user is referring to. In their paper \n",
      "Automated interpretation of place descriptions: determining \n",
      "entity types for querying OSM, Madiha Yousaf, Tobias \n",
      "Schwartz, and Diedrich Wolter present an approach that \n",
      "given a natural language input (a query) provides a ranked \n",
      "list of likely OpenStreetMap (OSM) tags that represent the \n",
      "entities referred to in the input. Noun-to-tag and tag-to-tag \n",
      "similarity is used to improve existing semantic similarity \n",
      "measures, such as word2vec or BERT, as demonstrated in \n",
      "an extensive evaluation.\n",
      "1.3  Project Report\n",
      "In the article UR Walking—Indoor navigation for research \n",
      "and daily use, Bernd Ludwig, Gregor Donabauer, Dominik \n",
      "Ramsauer and Karema Al Subari report about results of\n"
     ]
    }
   ],
   "source": [
    "question = \"What are authors of this document?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "print(docs_svm[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df78e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "626fc9bc",
   "metadata": {},
   "source": [
    "# Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13e03644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "persist_directory = 'data/chromaAI2x/'\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\") # mxbai-embed-large, llama3.2\n",
    "\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "# Load PDF\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(\"data/GeoAI.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1bc5294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "114d6165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21005"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joined_page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f2904eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0294187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOllama\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9ed17e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is geographic information retrieval (GIR)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb6a5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever())\n",
    "# qa.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2bffe97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographic Information Retrieval (GIR) is a subfield of Geographic Information Science (GIScience) and Computer Science. It involves the search and retrieval of geospatial data, such as maps, images, and other location-based information.\n",
      "\n",
      "GIR aims to enable users to efficiently locate, extract, and analyze relevant spatial data from large collections of geospatial content, such as satellite imagery, aerial photography, or geographic databases. The goal is to provide users with relevant and accurate results for their search queries, taking into account the spatial context and relationships between different locations.\n",
      "\n",
      "Some common applications of GIR include:\n",
      "\n",
      "* Map-based search engines\n",
      "* Location-based information retrieval systems\n",
      "* Image and video analysis for disaster response and recovery\n",
      "* Geospatial data mining and analytics\n",
      "\n",
      "GIR draws on concepts from computer science, such as information retrieval, natural language processing, and machine learning, to develop algorithms and techniques that can efficiently process and analyze large datasets of geospatial content.\n"
     ]
    }
   ],
   "source": [
    "result = qa({\"query\": question})  \n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "495570ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know the answer to that question, but I can try to provide some context about Geographic Information Science (GIScience) and its related fields.\\n\\nGeographic Information Science (GIScience) is an interdisciplinary field that deals with the acquisition, processing, analysis, and dissemination of geographically referenced data. It encompasses various aspects of geographic information, including spatial data, cartography, geographic modeling, and geographic computing.\\n\\nGeographic Information Retrieval (GIR) is a subfield within GIScience that focuses on the retrieval of relevant geographic information from large collections of text documents, images, or other types of data. The goal of GIR is to enable efficient and accurate search for specific geographic entities, locations, or features in unstructured or semi-structured data.\\n\\nSome common tasks in GIR include:\\n\\n1. Entity disambiguation: Identifying the correct entity (e.g., location, feature, or concept) being referred to in a text.\\n2. Location identification: Determining the geographical location of an entity mentioned in a text.\\n3. Geographic information extraction: Extracting relevant geographic information from unstructured data sources, such as text documents or images.\\n\\nGIR has applications in various domains, including:\\n\\n1. Geographic question answering\\n2. Natural language processing (NLP)\\n3. Information retrieval\\n4. Spatial semantic reasoning\\n\\nIf you're interested in learning more about GIR, I can try to provide some additional resources or point you in the direction of relevant research papers and publications!\""
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa2 = RetrievalQA.from_chain_type(llm=llm, retriever=svm_retriever)\n",
    "qa2.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa2({\"query\": question})  \n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "267eda51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have any information about a document or who Krzysztof Janowicz is. Can you provide more context or details about the document and who Krzysztof Janowicz is? I'll do my best to help.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question2 = \"Who is Krzysztof Janowicz in the document?\"\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever())\n",
    "qa.run(question2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
